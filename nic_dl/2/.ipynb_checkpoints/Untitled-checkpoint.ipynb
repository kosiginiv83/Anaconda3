{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11476992/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape([-1, 28*28]) / 255.\n",
    "X_test = x_test.reshape([-1, 28*28]) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(28*28,), init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(10, init=init, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, input_shape=(784,), activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\Anaconda_pf\\lib\\site-packages\\keras\\models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 5s - loss: 2.3008 - acc: 0.1132 - val_loss: 2.2990 - val_acc: 0.1135\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s - loss: 2.2971 - acc: 0.1124 - val_loss: 2.2940 - val_acc: 0.1135\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s - loss: 2.2832 - acc: 0.1596 - val_loss: 2.2514 - val_acc: 0.2062\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s - loss: 1.9262 - acc: 0.2554 - val_loss: 1.6442 - val_acc: 0.3682\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s - loss: 1.3806 - acc: 0.4768 - val_loss: 1.1222 - val_acc: 0.6247\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.8604 - acc: 0.7109 - val_loss: 0.6962 - val_acc: 0.8038\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.6109 - acc: 0.8247 - val_loss: 0.5351 - val_acc: 0.8494\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.5049 - acc: 0.8581 - val_loss: 0.4659 - val_acc: 0.8679\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.4476 - acc: 0.8745 - val_loss: 0.4138 - val_acc: 0.8812\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.3996 - acc: 0.8872 - val_loss: 0.3700 - val_acc: 0.8954\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.3548 - acc: 0.9007 - val_loss: 0.3470 - val_acc: 0.9052\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.3167 - acc: 0.9111 - val_loss: 0.3000 - val_acc: 0.9152\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.2848 - acc: 0.9206 - val_loss: 0.2749 - val_acc: 0.9232\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2568 - acc: 0.9275 - val_loss: 0.2476 - val_acc: 0.9319\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2339 - acc: 0.9347 - val_loss: 0.2304 - val_acc: 0.9363\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.2132 - acc: 0.9401 - val_loss: 0.2118 - val_acc: 0.9413\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1956 - acc: 0.9446 - val_loss: 0.1995 - val_acc: 0.9431\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1795 - acc: 0.9497 - val_loss: 0.1879 - val_acc: 0.9491\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 6s - loss: 0.1674 - acc: 0.9525 - val_loss: 0.1759 - val_acc: 0.9507\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1565 - acc: 0.9559 - val_loss: 0.1731 - val_acc: 0.9510\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1459 - acc: 0.9579 - val_loss: 0.1749 - val_acc: 0.9514\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1376 - acc: 0.9608 - val_loss: 0.1526 - val_acc: 0.9566\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1292 - acc: 0.9628 - val_loss: 0.1468 - val_acc: 0.9585\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1220 - acc: 0.9648 - val_loss: 0.1465 - val_acc: 0.9576\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1161 - acc: 0.9666 - val_loss: 0.1373 - val_acc: 0.9598\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1099 - acc: 0.9686 - val_loss: 0.1329 - val_acc: 0.9629\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1041 - acc: 0.9704 - val_loss: 0.1327 - val_acc: 0.9612\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0996 - acc: 0.9719 - val_loss: 0.1302 - val_acc: 0.9612\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0940 - acc: 0.9729 - val_loss: 0.1213 - val_acc: 0.9649\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0903 - acc: 0.9743 - val_loss: 0.1241 - val_acc: 0.9647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1b9d5e390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_model = create_model(\"uniform\")\n",
    "uniform_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "uniform_model.fit(X_train, Y_train, batch_size=64, nb_epoch=30, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, input_shape=(784,), activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  \"\"\"\n",
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "C:\\Anaconda_pf\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_normal\")`\n",
      "  import sys\n",
      "C:\\Anaconda_pf\\lib\\site-packages\\keras\\models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.8605 - acc: 0.7897 - val_loss: 0.4208 - val_acc: 0.8939\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.3751 - acc: 0.8974 - val_loss: 0.3213 - val_acc: 0.9105\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.3115 - acc: 0.9117 - val_loss: 0.2824 - val_acc: 0.9207\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2789 - acc: 0.9193 - val_loss: 0.2573 - val_acc: 0.9278\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2547 - acc: 0.9260 - val_loss: 0.2396 - val_acc: 0.9317\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.2353 - acc: 0.9318 - val_loss: 0.2238 - val_acc: 0.9361\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2182 - acc: 0.9363 - val_loss: 0.2083 - val_acc: 0.9374\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2026 - acc: 0.9407 - val_loss: 0.1972 - val_acc: 0.9409\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1886 - acc: 0.9450 - val_loss: 0.1828 - val_acc: 0.9441\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1756 - acc: 0.9491 - val_loss: 0.1716 - val_acc: 0.9489\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1642 - acc: 0.9526 - val_loss: 0.1631 - val_acc: 0.9510\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1535 - acc: 0.9558 - val_loss: 0.1561 - val_acc: 0.9541\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1443 - acc: 0.9582 - val_loss: 0.1467 - val_acc: 0.9553\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1355 - acc: 0.9610 - val_loss: 0.1386 - val_acc: 0.9585\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1278 - acc: 0.9630 - val_loss: 0.1344 - val_acc: 0.9602\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1209 - acc: 0.9649 - val_loss: 0.1301 - val_acc: 0.9602\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1141 - acc: 0.9678 - val_loss: 0.1237 - val_acc: 0.9630\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1083 - acc: 0.9687 - val_loss: 0.1182 - val_acc: 0.9642\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1024 - acc: 0.9708 - val_loss: 0.1146 - val_acc: 0.9648\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0978 - acc: 0.9717 - val_loss: 0.1108 - val_acc: 0.9660\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0931 - acc: 0.9731 - val_loss: 0.1093 - val_acc: 0.9659\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0888 - acc: 0.9749 - val_loss: 0.1065 - val_acc: 0.9663\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0846 - acc: 0.9762 - val_loss: 0.1033 - val_acc: 0.9687\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0807 - acc: 0.9768 - val_loss: 0.1038 - val_acc: 0.9688\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0772 - acc: 0.9784 - val_loss: 0.0984 - val_acc: 0.9693\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0736 - acc: 0.9791 - val_loss: 0.0974 - val_acc: 0.9698\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0709 - acc: 0.9798 - val_loss: 0.0940 - val_acc: 0.9703\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0674 - acc: 0.9808 - val_loss: 0.0922 - val_acc: 0.9711\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0647 - acc: 0.9819 - val_loss: 0.0937 - val_acc: 0.9700\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0618 - acc: 0.9824 - val_loss: 0.0903 - val_acc: 0.9716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1ba59fb38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glorot_model = create_model(\"glorot_normal\")\n",
    "glorot_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "glorot_model.fit(X_train, Y_train, batch_size=64, nb_epoch=30, verbose=1, validation_data=(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
