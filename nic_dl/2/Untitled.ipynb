{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11476992/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape([-1, 28*28]) / 255.\n",
    "X_test = x_test.reshape([-1, 28*28]) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(784,), kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(100, kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(100, kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(100, kernel_initializer=init, activation='tanh'))\n",
    "    model.add(Dense(10, kernel_initializer=init, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 5s - loss: 2.3009 - acc: 0.1116 - val_loss: 2.2990 - val_acc: 0.1135\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s - loss: 2.2968 - acc: 0.1124 - val_loss: 2.2931 - val_acc: 0.1135\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s - loss: 2.2750 - acc: 0.1578 - val_loss: 2.2063 - val_acc: 0.2390\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s - loss: 1.7807 - acc: 0.3219 - val_loss: 1.4389 - val_acc: 0.4188\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s - loss: 1.2841 - acc: 0.4990 - val_loss: 1.1627 - val_acc: 0.5753\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.9893 - acc: 0.6596 - val_loss: 0.7998 - val_acc: 0.7366\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.7279 - acc: 0.7619 - val_loss: 0.6526 - val_acc: 0.8000\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.5847 - acc: 0.8302 - val_loss: 0.5052 - val_acc: 0.8590\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.4694 - acc: 0.8688 - val_loss: 0.4313 - val_acc: 0.8783\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.3995 - acc: 0.8884 - val_loss: 0.3692 - val_acc: 0.8988\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.3485 - acc: 0.9035 - val_loss: 0.3274 - val_acc: 0.9106\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.3084 - acc: 0.9148 - val_loss: 0.2993 - val_acc: 0.9165\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2748 - acc: 0.9230 - val_loss: 0.2750 - val_acc: 0.9230\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2466 - acc: 0.9312 - val_loss: 0.2620 - val_acc: 0.9270\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2234 - acc: 0.9368 - val_loss: 0.2264 - val_acc: 0.9368\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2043 - acc: 0.9425 - val_loss: 0.2188 - val_acc: 0.9387\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1881 - acc: 0.9469 - val_loss: 0.2028 - val_acc: 0.9433\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1751 - acc: 0.9502 - val_loss: 0.1938 - val_acc: 0.9483\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1637 - acc: 0.9540 - val_loss: 0.1779 - val_acc: 0.9517\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1537 - acc: 0.9566 - val_loss: 0.1711 - val_acc: 0.9535\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1451 - acc: 0.9592 - val_loss: 0.1647 - val_acc: 0.9550\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1367 - acc: 0.9622 - val_loss: 0.1668 - val_acc: 0.9527\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1289 - acc: 0.9640 - val_loss: 0.1599 - val_acc: 0.9560\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1230 - acc: 0.9652 - val_loss: 0.1547 - val_acc: 0.9595\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1171 - acc: 0.9677 - val_loss: 0.1509 - val_acc: 0.9585\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1113 - acc: 0.9691 - val_loss: 0.1540 - val_acc: 0.9576\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1065 - acc: 0.9702 - val_loss: 0.1437 - val_acc: 0.9601\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1022 - acc: 0.9712 - val_loss: 0.1448 - val_acc: 0.9606\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0974 - acc: 0.9730 - val_loss: 0.1377 - val_acc: 0.9623\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0928 - acc: 0.9738 - val_loss: 0.1321 - val_acc: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1bc08ee80>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_model = create_model(\"uniform\")\n",
    "uniform_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "uniform_model.fit(X_train, Y_train, batch_size=64, epochs=30, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.8657 - acc: 0.7883 - val_loss: 0.4247 - val_acc: 0.8885\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.3740 - acc: 0.8967 - val_loss: 0.3197 - val_acc: 0.9098\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.3077 - acc: 0.9126 - val_loss: 0.2795 - val_acc: 0.9200\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2732 - acc: 0.9206 - val_loss: 0.2544 - val_acc: 0.9271\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2484 - acc: 0.9283 - val_loss: 0.2379 - val_acc: 0.9298\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2281 - acc: 0.9342 - val_loss: 0.2178 - val_acc: 0.9370\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.2106 - acc: 0.9385 - val_loss: 0.2044 - val_acc: 0.9393\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1949 - acc: 0.9435 - val_loss: 0.1883 - val_acc: 0.9447\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1809 - acc: 0.9474 - val_loss: 0.1782 - val_acc: 0.9475\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1685 - acc: 0.9503 - val_loss: 0.1686 - val_acc: 0.9506\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1570 - acc: 0.9539 - val_loss: 0.1554 - val_acc: 0.9537\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1471 - acc: 0.9568 - val_loss: 0.1484 - val_acc: 0.9550\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1381 - acc: 0.9599 - val_loss: 0.1401 - val_acc: 0.9571\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1298 - acc: 0.9624 - val_loss: 0.1372 - val_acc: 0.9589\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1227 - acc: 0.9648 - val_loss: 0.1289 - val_acc: 0.9608\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1158 - acc: 0.9667 - val_loss: 0.1227 - val_acc: 0.9621\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.1096 - acc: 0.9681 - val_loss: 0.1196 - val_acc: 0.9638\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.1040 - acc: 0.9703 - val_loss: 0.1131 - val_acc: 0.9651\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0990 - acc: 0.9717 - val_loss: 0.1094 - val_acc: 0.9667\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0939 - acc: 0.9730 - val_loss: 0.1093 - val_acc: 0.9668\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0897 - acc: 0.9745 - val_loss: 0.1052 - val_acc: 0.9677\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0855 - acc: 0.9759 - val_loss: 0.1028 - val_acc: 0.9676\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0819 - acc: 0.9768 - val_loss: 0.0997 - val_acc: 0.9693\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0783 - acc: 0.9779 - val_loss: 0.0975 - val_acc: 0.9687\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0747 - acc: 0.9786 - val_loss: 0.0983 - val_acc: 0.9701\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0716 - acc: 0.9795 - val_loss: 0.0922 - val_acc: 0.9714\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0685 - acc: 0.9807 - val_loss: 0.0952 - val_acc: 0.9690\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s - loss: 0.0656 - acc: 0.9815 - val_loss: 0.0908 - val_acc: 0.9718\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0627 - acc: 0.9824 - val_loss: 0.0889 - val_acc: 0.9717\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 5s - loss: 0.0606 - acc: 0.9826 - val_loss: 0.0907 - val_acc: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1bc57d588>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glorot_model = create_model(\"glorot_normal\")\n",
    "glorot_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "glorot_model.fit(X_train, Y_train, batch_size=64, epochs=30, verbose=1, validation_data=(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
